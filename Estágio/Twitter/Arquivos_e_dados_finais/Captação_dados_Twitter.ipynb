{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Captação_dados_Twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanCarloTS/Machine-Learning-Projects/blob/main/Est%C3%A1gio/Capta%C3%A7%C3%A3o_dados_Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8JIH59oiXqC"
      },
      "source": [
        "# **Referência única**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPRmA9CicSI"
      },
      "source": [
        "https://towardsdatascience.com/twitter-data-collection-tutorial-using-python-3267d7cfa93e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5wdC8oph8CQ"
      },
      "source": [
        "# **Bibliotecas e instalações**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39g9QnNhyCgH"
      },
      "source": [
        "# Importando todas as bibliotecas requeridas\n",
        "import tweepy                   # Biblioteca para acesso ao Twitter API usando Python\n",
        "from google.colab import drive  # Importando o Google Drive para usar nesse Colab notebook\n",
        "import json                     # Biblioteca para trabalhar com arquivos json\n",
        "import csv                      # Biblioteca para trabalhar com arquivos csv\n",
        "from datetime import date       # Biblioteca para capturar dados de data/horário\n",
        "from datetime import datetime\n",
        "import time                     # Biblioteca para contabilizar o tempo de execução do código\n",
        "import pandas as pd             # Biblioteca para manipulação e analise de dados\n",
        "import numpy as np              # Biblioteca para manipulações matemáticas (arrays, matrizes e etc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6mHsCB3PTS"
      },
      "source": [
        "# **Driver**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq_7Si0lyxa3",
        "outputId": "a52ed5e3-9ffc-467a-f6d2-6dd55383be09"
      },
      "source": [
        "# Conectando o Google Drive a este Colab Notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFnL5P79yJP6"
      },
      "source": [
        "# Criando uma variável, a qual conterá o caminho onde serão localizados os dados\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Estágio - IMT & NPL Brasil/Primeira Semana'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q57i5X91iHHa"
      },
      "source": [
        "# **Chaves do Twitter como desenvolvedor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969-kmP0ySG3"
      },
      "source": [
        "api_key = 'hi1jHROTuqYXaCnotHQxveKdD'\n",
        "\n",
        "api_secret_key = 'JzkHwN5wwBDlVMTvmGJovciAwh1PNLRQr3gmZbWpjDb6rgjDv2'\n",
        "\n",
        "access_token = '1396838828263059457-nM3a0PfGomJa2BYjz2cj7qJWS4bcvE'\n",
        "\n",
        "access_token_secret = 'l9C224MHomQL0HT3QVnG3QmqJra4ANCgIYEGUkopi459A'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYt47xjmjdaM"
      },
      "source": [
        "# Conecta ao Twitter API usando as chaves e tokens\n",
        "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQhqcojeiOUE"
      },
      "source": [
        "# **Funções proprietárias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahKuCEOXnxW5"
      },
      "source": [
        "# Função que facilita o armazenamento de dados em um arquivo JSON no Google Drive\n",
        "# file_name: Nome do arquivo localizado no Google Drive\n",
        "# file_content: O conteúdo ou dado que deseja ser salvo no arquivo\n",
        "def save_json(file_name, file_content):\n",
        "  with open(path + file_name, 'w', encoding='utf-8') as f:\n",
        "    json.dump(file_content, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54mdfKfrn02e"
      },
      "source": [
        "# Função para tratar o tempo limite do twitter API\n",
        "def limit_handled(cursor, list_name):\n",
        "  while True:\n",
        "    try:\n",
        "      yield cursor.next()\n",
        "    # Captura a excessão do tempo limite do Twitter API e espera por 15 minutos\n",
        "    except tweepy.RateLimitError:\n",
        "      print(\"\\nData points listados = {}\".format(len(list_name)))\n",
        "      print('Alcançou o tempo limite do Twitter API.')\n",
        "      for i in range(3, 0, -1):\n",
        "        print(\"Esperando por {} minutos.\".format(i * 5))\n",
        "        time.sleep(5 * 60)\n",
        "    # Captura qualquer outra excessão do Twitter API\n",
        "    except tweepy.error.TweepError:\n",
        "      print('\\nExcessão no TweepError capturada' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I22dOodPn8Fv"
      },
      "source": [
        "# Função para pegar tweets de um usuário específico \n",
        "# NOTE: Esse metódo tem capacidade de pegar apenas os 3200 tweets mais recentes.\n",
        "# Source: https://gist.github.com/yanofsky/5436496\n",
        "\n",
        "def get_all_tweets(screen_name):\n",
        "\n",
        "  # Inicia uma lista para guardar todos os Tweets\n",
        "  alltweets = []\n",
        "\n",
        "  # Faz um requerimento inicial dos tweets mais recentes \n",
        "  # (200 é o maximo permitido)\n",
        "  new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
        "\n",
        "  # Salva os tweets mais recentes\n",
        "  alltweets.extend(new_tweets)\n",
        "\n",
        "  # Salva o ID do ultimo tweet, permitindo que o processo seja repetido\n",
        "  oldest = alltweets[-1].id - 1\n",
        "\n",
        "  # Enquanto houver tweets restantes, continue capturando todos  \n",
        "  while len(new_tweets) > 0:\n",
        "    print(\"getting tweets before %s\" % (oldest))\n",
        "    # Todos as proximas requisições usam o parametro max_id para evitar duplicatas\n",
        "    new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
        "    # Salva os tweets mais recentes\n",
        "    alltweets.extend(new_tweets)\n",
        "    # Salva o ID do ultimo tweet, permitindo que o processo seja repetido\n",
        "    oldest = alltweets[-1].id - 1\n",
        "    print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
        "    ### END OF WHILE LOOP ###\n",
        "\n",
        "  # Transformar todos os Tweets capturados pela tweepy em um array 2D que vai gerar conteúdo pro arquivo csv\n",
        "  outtweets = [[tweet.id_str, tweet.created_at, tweet.text, tweet.favorite_count,tweet.in_reply_to_screen_name, tweet.retweeted] for tweet in alltweets]\n",
        "  # Cria o csv\n",
        "  with open(path + \"_\" + '%s_tweets.csv' % screen_name, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"id\",\"created_at\",\"text\",\"likes\",\"in reply to\",\"retweeted\"])\n",
        "    writer.writerows(outtweets)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Px_qX0oAJs"
      },
      "source": [
        "# Função para salvar os objetos de seguidores em um aquivo JSON.\n",
        "def get_followers():\n",
        "  \n",
        "  # Cria uma lista para armazenar os dados de seguidores \n",
        "  followers_list = []\n",
        "  # For-loop para interagir com o cursor da biblioteca tweepy\n",
        "  cursor = tweepy.Cursor(api.followers, count=200).pages()\n",
        "  for i, page in enumerate(limit_handled(cursor, followers_list)):  \n",
        "    print(\"\\r\"+\"Loading\"+ i % 5 *\".\", end='')\n",
        "    \n",
        "    # Adiciona o ultimo conjunto de seguidores à lista\n",
        "    followers_list += page\n",
        "  \n",
        "  # Extrai o conteúdo dos seguidores\n",
        "  followers_list = [x._json for x in followers_list]\n",
        "  # Salva os dados em um arquivo JSON\n",
        "  save_json('followers_data.json', followers_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcrQPYiboDMj"
      },
      "source": [
        "# Função para salvar os objetos de amigos em um aquivo JSON.\n",
        "def get_friends():\n",
        "  \n",
        "  # Cria uma lista para armazenar os dados de amigos \n",
        "  friends_list = []\n",
        "  # For-loop para interagir com o cursor da biblioteca tweepy\n",
        "  cursor = tweepy.Cursor(api.friends, count=200).pages()\n",
        "  for i, page in enumerate(limit_handled(cursor, friends_list)):  \n",
        "    print(\"\\r\"+\"Loading\"+ i % 5 *\".\", end='')\n",
        "    \n",
        "    # Adiciona o ultimo conjunto de amigos à lista\n",
        "    friends_list += page\n",
        "  \n",
        "  # Extrai o conteúdo dos amigos\n",
        "  friends_list = [x._json for x in friends_list]\n",
        "  # Salva os dados em um arquivo JSON\n",
        "  save_json('friends_data.json', friends_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ro6ZFP_oGfq"
      },
      "source": [
        "# Função para salvar numero de seguidos e seguidores em um arquivo JSON\n",
        "def todays_stats(dict_name):\n",
        "  # Pega a minha informação de usuário \n",
        "  info = api.me()\n",
        "  # Conta o numero de seguidos e seguidores\n",
        "  followers_cnt = info.followers_count  \n",
        "  following_cnt = info.friends_count\n",
        "  # Armazena a data de hoje\n",
        "  today = date.today()\n",
        "  d = today.strftime(\"%b %d, %Y\")\n",
        "  # Se não foram capturadas, salva o status do dia\n",
        "  if d not in dict_name:\n",
        "    dict_name[d] = {\"followers\":followers_cnt, \"following\":following_cnt}\n",
        "    save_json(\"follower_history.json\", dict_name)\n",
        "  else:\n",
        "    print('Today\\'s stats already exist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygew_3EJiT9p"
      },
      "source": [
        "# **Uso das funções**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2UIultppB-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d87d71-1e9c-4495-a353-a1fc8ad8e3c3"
      },
      "source": [
        "get_all_tweets('jornaldobrasil')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting tweets before 1396906575130996735\n",
            "...399 tweets downloaded so far\n",
            "getting tweets before 1393556913456091149\n",
            "...598 tweets downloaded so far\n",
            "getting tweets before 1390453532831191042\n",
            "...798 tweets downloaded so far\n",
            "getting tweets before 1387596687577845762\n",
            "...998 tweets downloaded so far\n",
            "getting tweets before 1383793846518116352\n",
            "...1198 tweets downloaded so far\n",
            "getting tweets before 1380923443231752206\n",
            "...1397 tweets downloaded so far\n",
            "getting tweets before 1378498319685652482\n",
            "...1595 tweets downloaded so far\n",
            "getting tweets before 1375910274838974466\n",
            "...1795 tweets downloaded so far\n",
            "getting tweets before 1373103846470344705\n",
            "...1994 tweets downloaded so far\n",
            "getting tweets before 1370174275030822915\n",
            "...2194 tweets downloaded so far\n",
            "getting tweets before 1368254377664933887\n",
            "...2393 tweets downloaded so far\n",
            "getting tweets before 1365650670133661699\n",
            "...2592 tweets downloaded so far\n",
            "getting tweets before 1363624031115767811\n",
            "...2791 tweets downloaded so far\n",
            "getting tweets before 1360373263306743813\n",
            "...2990 tweets downloaded so far\n",
            "getting tweets before 1356700832272646143\n",
            "...3190 tweets downloaded so far\n",
            "getting tweets before 1353027418676719615\n",
            "...3240 tweets downloaded so far\n",
            "getting tweets before 1351617898494701567\n",
            "...3240 tweets downloaded so far\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvACnGupXma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "77e53376-b96c-4e98-c25b-5e6d7441c662"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Estágio - IMT & NPL Brasil/Primeira Semana_jornaldobrasil_tweets.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>likes</th>\n",
              "      <th>in reply to</th>\n",
              "      <th>retweeted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1399352005051793426</td>\n",
              "      <td>2021-05-31 13:08:11</td>\n",
              "      <td>[DO LEITOR]\\n\"O governador de Pernambuco @Paul...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1399351075073822729</td>\n",
              "      <td>2021-05-31 13:04:29</td>\n",
              "      <td>RT @brasil247: Globalistas - Como a imprensa i...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1399350566644551687</td>\n",
              "      <td>2021-05-31 13:02:28</td>\n",
              "      <td>RT @RhangelRibeiro: Tá aí o Pastor Cláudio Dua...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1399350475963633664</td>\n",
              "      <td>2021-05-31 13:02:06</td>\n",
              "      <td>RT @davidmirandario: Homens armados, usando as...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1399350402303381504</td>\n",
              "      <td>2021-05-31 13:01:49</td>\n",
              "      <td>RT @GeorgMarques: Globo e Estadão estão em cam...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3235</th>\n",
              "      <td>1351684782925737984</td>\n",
              "      <td>2021-01-20 00:15:39</td>\n",
              "      <td>RT @cirogomes: Que a China, a Índia e os demai...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3236</th>\n",
              "      <td>1351684717268107267</td>\n",
              "      <td>2021-01-20 00:15:24</td>\n",
              "      <td>RT @AndreaMPacha: Como é possível que diante d...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3237</th>\n",
              "      <td>1351684659810349058</td>\n",
              "      <td>2021-01-20 00:15:10</td>\n",
              "      <td>RT @reinaldoazevedo: Argentina fechou acordo c...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3238</th>\n",
              "      <td>1351684609008955395</td>\n",
              "      <td>2021-01-20 00:14:58</td>\n",
              "      <td>RT @fabioluizfranca: Dilma caiu por pedalar. B...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3239</th>\n",
              "      <td>1351617898494701568</td>\n",
              "      <td>2021-01-19 19:49:53</td>\n",
              "      <td>RT @MarceloFreixo: URGENTE: A Índia acaba de d...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3240 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id           created_at  ... in reply to  retweeted\n",
              "0     1399352005051793426  2021-05-31 13:08:11  ...         NaN      False\n",
              "1     1399351075073822729  2021-05-31 13:04:29  ...         NaN      False\n",
              "2     1399350566644551687  2021-05-31 13:02:28  ...         NaN      False\n",
              "3     1399350475963633664  2021-05-31 13:02:06  ...         NaN      False\n",
              "4     1399350402303381504  2021-05-31 13:01:49  ...         NaN      False\n",
              "...                   ...                  ...  ...         ...        ...\n",
              "3235  1351684782925737984  2021-01-20 00:15:39  ...         NaN      False\n",
              "3236  1351684717268107267  2021-01-20 00:15:24  ...         NaN      False\n",
              "3237  1351684659810349058  2021-01-20 00:15:10  ...         NaN      False\n",
              "3238  1351684609008955395  2021-01-20 00:14:58  ...         NaN      False\n",
              "3239  1351617898494701568  2021-01-19 19:49:53  ...         NaN      False\n",
              "\n",
              "[3240 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}